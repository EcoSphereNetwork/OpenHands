# API-Keys für LLM-Provider
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key

# Ollama-Konfiguration
# Kein API-Key nötig, da Ollama lokal läuft
OLLAMA_MODEL=llama3       # Das Standardmodell für Ollama
OLLAMA_HOST=ollama-server # Der Hostname des Ollama-Servers im Docker-Netzwerk

# GitHub-Konfiguration für Issue-Resolver
GITHUB_TOKEN=your-github-token
GIT_USERNAME=your-github-username

# Docker-Konfiguration
SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.30-nikolaik
WORKSPACE_MOUNT_PATH=/opt/workspace_base
